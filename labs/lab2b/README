NAME: Tanzeela Khan
EMAIL: tanzeelakhan@g.ucla.edu
ID: 204577214

---FILES---

lab2_add.c: Uses pthreads to add to a shared variable. Allows for enabling of different locks to stop race conditions.
SortedList.h: Supplied header file that describes the interfaces for the sorted linked list.
SortedList.c: Implements functions in Sorted List Header field to insert, delete, and lookup in the doubly linked list. 
Makefile: Builds deliverable wtih tests, profile, grahps, dist, and clean. 
lab2_list.c: Uses pthreads to add to a shared Sorted list. Allows for enabling of different locks to stop race conditions. 
lab2_add.csv: generated graph input from Makefile tests. lab2_add.gp uses this data to plot on gnuplot.
lab2_list.csv: generated graph input from Makefile tests. lab2_list.gp uses this data to plot on gnuplot.
lab2_add-1.png: threads and iterations required to generate a failure (with and without yields)
lab2_add-2.png: average time per operation with and without yields.
lab2_add-3.png: average time per (single threaded) operation vs. the number of iterations.
lab2_add-4.png: threads and iterations that can run successfully with yields under each of the synchronization options.
lab2_add-5.png: average time per (protected) operation vs. the number of threads.
lab2_list-1.png: average time per (single threaded) unprotected operation vs. number of iterations (illustrating the correction of the per-operation cost for the list length).
lab2_list-2.png: threads and iterations required to generate a failure (with and without yields).
lab2_list-3.png: iterations that can run (protected) without failure.
lab2_list-4.png: (length-adjusted) cost per operation vs the number of threads for the various synchronization options.


---QUESTIONS---

QUESTION 2.1.1 - causing conflicts:
Why does it take many iterations before errors are seen?
    Since there are more chacnes for a thread to be preempted during its execution, it usally takes more iteraitons before errors are seen. If time create is less than time execution, multiple threads are going to be updating the same value. If time create is greater than time exectuion, only one thread is updating the value. The greater the iterations, the greater the execution time before the errors are seen.

Why does a significantly smaller number of iterations so seldom fail?
    The lesser number of iterations results in a significaintly lesser execution time compared to the pthread_create time, so it's less likely to be preempted.

QUESTION 2.1.2 - cost of yielding:
Why are the --yield runs so much slower?
    Since sched_yield is a system call, it is an expensive and time-consuming operation involing a register bien gsaved and restored again. Yield also increases the chances of preemption and a context-switch happening, increasing time even more.
Where is the additional time going?
      Context switching uses up this time.
Is it possible to get valid per-operation timings if we are using the --yield option? If so, explain how. If not, explain why not.
   It is not possible, because context switches consume the bulk of the time, resulting in inaccurate per-operation timings. The overhead time is too large to determine how much time was spent on context switching.

QUESTION 2.1.3 - measurement errors:
Why does the average cost per operation drop with increasing iterations?
    With lesser iterations, most of the time is spent on pthread create. With more iterations, the cost of pthread create time becomes less significant in the cost.

If the cost per iteration is a function of the number of iterations, how do we know how many iterations to run (or what the "correct" cost is)?
   With increasing iterations, the cost of creating a thread convergest to near zero. The correct cost is determeind by whent he line stabilizes.

QUESTION 2.1.4 - costs of serialization:
Why do all of the options perform similarly for low numbers of threads?
    With a low number of threads, there is less compeitiotn for resources so options perform similarly. The options perform differently when there is a greater chance for race conditions for resources.  

Why do the three protected operations slow down as the number of threads rises?
    Since more threads are competing, race conditions increase and decrease performance speed.

QUESTION 2.2.1 - scalability of Mutex

Compare the variation in time per mutex-protected operation vs the number of threads in Part-1 (adds) and Part-2 (sorted lists).
	In both parts, mutex-protected operations increases with the number of threads intiitally. This changes eventually so that the addition cost increase.

Comment on the general shapes of the curves, and explain why they have this shape.
	The curves appear to be exponentionally decreasing with the mutex lock at a converging point in boht parts.This occurs because the steps in the crtical section is greater in list than it is in the add operations. As a result, there is more competition for resources and increases the chances of preemeption int the list operations. 

Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.
	Since the critical section area in list involves more steps than it does in list, the odds of preemption in list are much higher than they are in add. The race for resources increases and preemption is affected more significantly in list. 
	
QUESTION 2.2.2 - scalability of spin locks
Compare the variation in time per protected operation vs the number of threads for list operations protected by Mutex vs Spin locks. Comment on the general shapes of the curves, and explain why they have this shape.
	The curve for the mutex uses less than time than the one for the spin lock. While they both show a graph with a postive sloep (increasing), this is inveitable since competition for resouces increases. Spin locks do worse because they waste a lot of CPU resources and "spinning" wait. This problem increases with time as shown by the graph.



---SOURCES---

CS111 TA Slides for DiscussionB
"Random String generator in C", AntonioCS, https://codereview.stackexchange.com/questions/29198/random-string-generator-in-c
"Pthreads Overview", Lawrence Livermore National Laboratory, https://computing.llnl.gov/tutorials/pthreads/#Designing
"Built-in functions for atomic memory access", gcc.gnu.org, https://gcc.gnu.org/onlinedocs/gcc-4.4.5/gcc/Atomic-Builtins.html
"clock_gettime(3) - Linux man page", linux.die.net, https://linux.die.net/man/3/clock_gettime
